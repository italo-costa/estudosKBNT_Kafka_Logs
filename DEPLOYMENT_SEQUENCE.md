# üöÄ Guia Completo: Levantando a Aplica√ß√£o KBNT Kafka Logs
## Steps Sequenciais Multi-Plataforma (Windows, Linux, macOS)

> **üìù Baseado em Experi√™ncias Reais**: Este guia foi criado a partir das dificuldades e solu√ß√µes encontradas durante o desenvolvimento e testes da aplica√ß√£o KBNT Kafka Logs.

---

## üìã **Pr√©-Requisitos Essenciais**

### üîß **Ferramentas Obrigat√≥rias**
- **Docker** >= 20.10.0
- **Docker Compose** >= 2.0.0
- **Git** >= 2.30.0
- **Python** >= 3.9.0
- **Java** >= 17 (OpenJDK recomendado)
- **Node.js** >= 16.0.0 (opcional para desenvolvimento)

### üñ•Ô∏è **Configura√ß√µes por Sistema Operacional**

#### **Windows 10/11**
```powershell
# Op√ß√£o 1: Docker Desktop (Recomendado)
# Instalar Docker Desktop com WSL2 backend
# https://docs.docker.com/desktop/windows/

# Op√ß√£o 2: WSL2 + Docker Engine (Advanced)
wsl --install -d Ubuntu
wsl --set-default Ubuntu
```

#### **Linux (Ubuntu/Debian)**
```bash
# Instalar Docker Engine
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# Instalar Docker Compose
sudo apt-get update
sudo apt-get install docker-compose-plugin
```

#### **macOS**
```bash
# Via Homebrew
brew install --cask docker
brew install docker-compose

# Via Docker Desktop
# https://docs.docker.com/desktop/mac/
```

---

## üõ†Ô∏è **PASSO 1: Prepara√ß√£o do Ambiente**

### **1.1 Clonar o Reposit√≥rio**
```bash
git clone https://github.com/italo-costa/estudosKBNT_Kafka_Logs.git
cd estudosKBNT_Kafka_Logs
```

### **1.2 Verificar Ferramentas (CR√çTICO)**
```bash
# Verificar Docker
docker --version
# Esperado: Docker version 20.10.x ou superior

# Verificar Docker Compose
docker compose version
# Esperado: Docker Compose version 2.x.x

# Verificar se Docker est√° rodando
docker ps
# Se der erro: iniciar Docker Desktop ou service docker start
```

### **1.3 Configurar Permiss√µes (Linux)**
```bash
# Adicionar usu√°rio ao grupo docker
sudo usermod -aG docker $USER
newgrp docker

# Verificar permiss√µes
docker run hello-world
```

---

## üê≥ **PASSO 2: Escolher Estrat√©gia de Deployment**

### **Estrat√©gias Dispon√≠veis** (baseadas nos nossos testes)

#### **üî∞ Free Tier** - Desenvolvimento/Teste
- **Containers**: 8
- **Recursos**: Baixos
- **Performance**: ~500 RPS
- **Uso**: Prova de conceito

#### **üìä Scalable Simple** - Desenvolvimento Avan√ßado  
- **Containers**: 15
- **Recursos**: Moderados
- **Performance**: ~2,300 RPS
- **Uso**: Testes de carga

#### **üèóÔ∏è Scalable Complete** - Pr√©-Produ√ß√£o
- **Containers**: 25
- **Recursos**: Altos
- **Performance**: ~10,400 RPS
- **Uso**: Homologa√ß√£o

#### **üèÜ Enterprise** - Produ√ß√£o
- **Containers**: 40
- **Recursos**: M√°ximos
- **Performance**: ~27,400 RPS
- **Uso**: Produ√ß√£o enterprise

---

## üöÄ **PASSO 3: Levantando a Aplica√ß√£o**

### **3.1 Navega√ß√£o para Diret√≥rio Docker**
```bash
cd docker/
ls -la
# Verificar se existem os arquivos docker-compose-*.yml
```

### **3.2 Escolher e Executar Strategy**

#### **Op√ß√£o A: Free Tier (Recomendado para In√≠cio)**
```bash
# Windows (PowerShell/CMD)
docker compose -f docker-compose.free-tier.yml up -d

# Linux/macOS
docker compose -f docker-compose.free-tier.yml up -d

# WSL2 (se houver problemas)
wsl -d Ubuntu -- bash -c "cd /mnt/c/workspace/estudosKBNT_Kafka_Logs/docker && docker compose -f docker-compose.free-tier.yml up -d"
```

#### **Op√ß√£o B: Scalable Simple**
```bash
docker compose -f docker-compose.scalable-simple.yml up -d
```

#### **Op√ß√£o C: Scalable Complete**
```bash
docker compose -f docker-compose.scalable.yml up -d
```

#### **Op√ß√£o D: Enterprise**
```bash
docker compose -f docker-compose.yml up -d
```

### **3.3 Verifica√ß√£o de Inicializa√ß√£o**
```bash
# Verificar containers em execu√ß√£o
docker ps

# Verificar logs (se houver problemas)
docker compose -f docker-compose.free-tier.yml logs

# Verificar recursos do sistema
docker stats
```

---

## üîç **PASSO 4: Valida√ß√£o e Troubleshooting**

### **4.1 Verificar Servi√ßos Ativos**
```bash
# Health check dos principais servi√ßos
curl -f http://localhost:8080/health || echo "API Gateway n√£o est√° respondendo"
curl -f http://localhost:8081/actuator/health || echo "Virtual Stock Service n√£o est√° respondendo"  
curl -f http://localhost:8082/actuator/health || echo "KBNT Log Service n√£o est√° respondendo"

# Verificar Kafka
docker exec -it $(docker ps -q -f "name=kafka") kafka-topics --bootstrap-server localhost:9092 --list

# Verificar PostgreSQL
docker exec -it $(docker ps -q -f "name=postgres") psql -U admin -d kbnt_logs -c "SELECT version();"

# Verificar Elasticsearch
curl -f http://localhost:9200/_cluster/health || echo "Elasticsearch n√£o est√° respondendo"

# Verificar Redis
docker exec -it $(docker ps -q -f "name=redis") redis-cli ping
```

### **4.2 Problemas Comuns e Solu√ß√µes**

#### **üö® Erro: "Port already in use"**
```bash
# Verificar portas em uso
netstat -tulpn | grep :8080
# ou no Windows:
netstat -an | findstr :8080

# Matar processos nas portas
sudo kill -9 $(sudo lsof -t -i:8080)
# ou no Windows:
taskkill /f /pid $(netstat -ano | findstr :8080 | awk '{print $5}')
```

#### **üö® Erro: "No space left on device"**
```bash
# Limpar containers e volumes √≥rf√£os
docker system prune -a --volumes

# Limpar imagens n√£o utilizadas
docker image prune -a

# Verificar espa√ßo
docker system df
```

#### **üö® Erro: "permission denied" (Linux)**
```bash
# Corrigir permiss√µes Docker
sudo chmod 666 /var/run/docker.sock

# Ou reiniciar servi√ßo Docker
sudo systemctl restart docker
```

#### **üö® Erro: Docker Compose n√£o encontrado**
```bash
# Linux - Instalar plugin
sudo apt-get install docker-compose-plugin

# Verificar instala√ß√£o
docker compose version
```

#### **üö® Containers ficam reiniciando**
```bash
# Verificar logs detalhados
docker compose -f docker-compose.free-tier.yml logs --follow

# Verificar recursos do sistema
free -h  # Linux
Get-ComputerInfo | Select-Object TotalPhysicalMemory,AvailablePhysicalMemory  # Windows

# Aumentar timeout se necess√°rio
docker compose -f docker-compose.free-tier.yml up -d --wait-timeout 300
```

---

## üß™ **PASSO 5: Executar Testes de Valida√ß√£o**

### **5.1 Configurar Ambiente Python**
```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/macOS:
source venv/bin/activate

# Instalar depend√™ncias
pip install -r requirements.txt
```

### **5.2 Executar Teste de Valida√ß√£o R√°pida**
```bash
# Teste b√°sico (1000 requisi√ß√µes)
python performance-test-simulation.py

# Teste espec√≠fico da estrat√©gia ativa
python performance-test-simple.py
```

### **5.3 Monitoramento em Tempo Real**
```bash
# Monitorar containers
watch 'docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"'

# Monitorar recursos
watch 'docker stats --no-stream'

# Logs em tempo real
docker compose -f docker-compose.free-tier.yml logs --follow --tail=50
```

---

## üìä **PASSO 6: Acessar Dashboards e Interfaces**

### **6.1 URLs dos Servi√ßos**
- **API Gateway**: http://localhost:8080
- **Virtual Stock Service**: http://localhost:8081
- **KBNT Log Service**: http://localhost:8082
- **Elasticsearch**: http://localhost:9200
- **Kibana** (se dispon√≠vel): http://localhost:5601
- **Redis Commander** (se dispon√≠vel): http://localhost:8081

### **6.2 Dashboard Interativo**
```bash
# Abrir dashboard de testes
# Windows:
start docs/diagrama_dados_testes_interativo_corrigido.html
# Linux:
xdg-open docs/diagrama_dados_testes_interativo_corrigido.html  
# macOS:
open docs/diagrama_dados_testes_interativo_corrigido.html
```

---

## üõë **PASSO 7: Parar e Limpar Ambiente**

### **7.1 Parar Aplica√ß√£o**
```bash
# Parar containers (mant√©m volumes)
docker compose -f docker-compose.free-tier.yml stop

# Parar e remover containers
docker compose -f docker-compose.free-tier.yml down

# Parar, remover containers E volumes
docker compose -f docker-compose.free-tier.yml down -v
```

### **7.2 Limpeza Completa (se necess√°rio)**
```bash
# Remover tudo relacionado ao projeto
docker compose -f docker-compose.free-tier.yml down -v --remove-orphans

# Limpeza geral do Docker
docker system prune -a --volumes

# Verificar limpeza
docker ps -a
docker volume ls
docker network ls
```

---

## üÜò **Resolu√ß√£o de Problemas Espec√≠ficos**

### **Problemas Identificados Durante Desenvolvimento:**

#### **1. WSL2 Path Issues (Windows)**
```bash
# Se o caminho n√£o for reconhecido
cd /mnt/c/workspace/estudosKBNT_Kafka_Logs/docker
# ao inv√©s de
cd C:\workspace\estudosKBNT_Kafka_Logs\docker
```

#### **2. Docker Compose Version Conflicts**
```bash
# Usar docker compose (n√£o docker-compose)
docker compose version  # ‚úÖ Correto
docker-compose version   # ‚ùå Vers√£o antiga
```

#### **3. Memory/Resource Constraints**
```bash
# Verificar recursos dispon√≠veis antes de subir
# M√≠nimo recomendado: 8GB RAM para Free Tier
# Enterprise Strategy: 16GB+ RAM recomendado

# Ajustar limites se necess√°rio
docker update --memory="4g" --cpus="2" $(docker ps -q)
```

#### **4. Network Port Conflicts**
```bash
# Verificar portas antes de subir
netstat -tlnp | grep -E ':8080|:8081|:8082|:9092|:5432|:9200|:6379'

# Se houver conflito, modificar docker-compose.yml
# Exemplo: trocar 8080:8080 para 8090:8080
```

#### **5. Volume Permission Issues (Linux)**
```bash
# Corrigir permiss√µes de volumes
sudo chown -R $USER:$USER ./data/
sudo chmod -R 755 ./data/
```

---

## ‚úÖ **Checklist de Valida√ß√£o Final**

### **Antes de Considerar Sucesso:**
- [ ] Todos os containers est√£o UP (docker ps)
- [ ] API Gateway responde (curl http://localhost:8080/health)
- [ ] Virtual Stock Service ativo (curl http://localhost:8081/actuator/health)
- [ ] KBNT Log Service ativo (curl http://localhost:8082/actuator/health)
- [ ] Kafka aceita conex√µes (port 9092)
- [ ] PostgreSQL aceita conex√µes (port 5432)
- [ ] Elasticsearch responde (curl http://localhost:9200/_cluster/health)
- [ ] Redis responde (docker exec redis redis-cli ping)
- [ ] Teste de performance executado com sucesso
- [ ] Dashboard interativo abre corretamente

### **Indicadores de Sucesso:**
- **Free Tier**: ~500 RPS, 8 containers ativos
- **Scalable Simple**: ~2,300 RPS, 15 containers ativos  
- **Scalable Complete**: ~10,400 RPS, 25 containers ativos
- **Enterprise**: ~27,400 RPS, 40 containers ativos

---

## üîó **Recursos Adicionais**

### **Logs e Monitoramento:**
```bash
# Ver logs espec√≠ficos
docker logs <container_name> --tail=100 --follow

# Monitoramento de recursos
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}\t{{.NetIO}}"

# Health check personalizado
curl -f http://localhost:8080/actuator/health | jq '.'
```

### **Backup e Restore:**
```bash
# Backup de volumes
docker run --rm -v kbnt_postgres_data:/data -v $(pwd):/backup alpine tar czf /backup/postgres_backup.tar.gz -C /data .

# Restore de volumes  
docker run --rm -v kbnt_postgres_data:/data -v $(pwd):/backup alpine tar xzf /backup/postgres_backup.tar.gz -C /data
```

---

## üéØ **Conclus√£o**

Este guia foi criado baseado nas **dificuldades reais** enfrentadas durante o desenvolvimento e testes da aplica√ß√£o KBNT Kafka Logs. Seguindo estes steps sequenciais, voc√™ deve conseguir levantar a aplica√ß√£o independente do sistema operacional.

**‚ö†Ô∏è IMPORTANTE**: Sempre come√ßar com **Free Tier** para validar o ambiente antes de tentar estrat√©gias mais complexas.

**üÜò Suporte**: Se encontrar problemas n√£o cobertos neste guia, verificar:
1. Logs dos containers (`docker compose logs`)
2. Recursos do sistema (`docker stats`)  
3. Vers√µes das ferramentas (`docker version`, `docker compose version`)
4. Permiss√µes de arquivo/diret√≥rio
5. Configura√ß√µes de firewall/antiv√≠rus

**üìß Contato**: Para suporte adicional, consultar a documenta√ß√£o do projeto ou abrir uma issue no reposit√≥rio GitHub.

---

## Sequ√™ncia de Inicializa√ß√£o por Ambiente

### Ambiente Local (docker-compose.yml)

```mermaid
sequenceDiagram
    participant User as User
    participant Docker as Docker
    participant PG as PostgreSQL
    participant ZK as ZooKeeper
    participant Kafka as Kafka
    participant VS as Virtual Stock
    participant API as API Gateway
    
    User->>Docker: docker-compose up -d
    Docker->>PG: Start PostgreSQL
    PG->>PG: Initialize database
    Docker->>ZK: Start ZooKeeper
    ZK->>ZK: Initialize cluster
    Docker->>Kafka: Start Kafka
    Kafka->>ZK: Connect to ZooKeeper
    Kafka->>Kafka: Create topics
    Docker->>VS: Start Virtual Stock
    VS->>PG: Connect to database
    VS->>Kafka: Connect to Kafka
    Docker->>API: Start API Gateway
    API->>VS: Register routes
    API->>User: Ready on :8080
```

### Ambiente Escal√°vel (docker-compose.scalable.yml)

```mermaid
sequenceDiagram
    participant User as User
    participant Docker as Docker
    participant PG as PostgreSQL Cluster
    participant ZK as ZooKeeper Cluster
    participant Kafka as Kafka Cluster
    participant ES as Elasticsearch
    participant LB as Load Balancer
    participant Mon as Monitoring
    participant Apps as Microservices
    
    User->>Docker: docker-compose.scalable.yml up -d
    
    par Infrastructure Setup
        Docker->>PG: Start PG Master + Replica
        Docker->>ZK: üöÄ Start ZK Ensemble (3 nodes)
        Docker->>ES: üöÄ Start ES Cluster (2 nodes)
        Docker->>Mon: üöÄ Start Prometheus + Grafana
    end
    
    PG->>PG: üîÑ Setup replication
    ZK->>ZK: üó≥Ô∏è Elect leader
    ES->>ES: ü§ù Form cluster
    
    Docker->>Kafka: üöÄ Start Kafka Cluster (3 brokers)
    Kafka->>ZK: üîó Register with ZooKeeper
    Kafka->>Kafka: üîÑ Setup partitions & replication
    
    Docker->>LB: üöÄ Start HAProxy
    LB->>LB: üìã Load balance config
    
    Docker->>Apps: üöÄ Start Multiple App Instances
    
    par Microservices Startup
        Apps->>PG: üîó Connect to database
        Apps->>Kafka: üîó Connect to brokers
        Apps->>ES: üîó Connect for logging
    end
    
    Apps->>LB: üìã Register with load balancer
    Mon->>Apps: üìä Start collecting metrics
    LB->>User: ‚úÖ System ready on multiple ports
```

---

## üîÑ Estrat√©gias de Deployment por Complexidade

### üìä Deployment Progressivo

```mermaid
graph TD
    A[üéØ Start Deployment] --> B{Select Strategy}
    
    %% N√≠vel 1: B√°sico
    B --> C[üì± Level 1: Basic]
    C --> C1[Single Instance]
    C1 --> C2[docker-compose.yml]
    C2 --> C3[6 Containers]
    C3 --> C4[‚úÖ Basic Setup Complete]
    
    %% N√≠vel 2: Teste
    B --> D[üß™ Level 2: Testing]
    D --> D1[Resource Limited]
    D1 --> D2[docker-compose.free-tier.yml]
    D2 --> D3[8 Containers + Constraints]
    D3 --> D4[‚úÖ Test Environment Ready]
    
    %% N√≠vel 3: Escal√°vel
    B --> E[üìà Level 3: Scalable]
    E --> E1[Multiple Instances]
    E1 --> E2[docker-compose.scalable-simple.yml]
    E2 --> E3[15 Containers + LB]
    E3 --> E4[‚úÖ Production Ready]
    
    %% N√≠vel 4: Enterprise
    B --> F[üè¢ Level 4: Enterprise]
    F --> F1[High Availability]
    F1 --> F2[docker-compose.scalable.yml]
    F2 --> F3[36+ Containers + Full HA]
    F3 --> F4[‚úÖ Enterprise Grade]
    
    %% Valida√ß√£o
    C4 --> G[üîç Validation Phase]
    D4 --> G
    E4 --> G
    F4 --> G
    
    G --> H[Health Checks]
    H --> I[Integration Tests]
    I --> J[Performance Tests]
    J --> K{All Tests Pass?}
    
    K -->|‚úÖ Yes| L[üéâ Deployment Success]
    K -->|‚ùå No| M[üîß Troubleshooting]
    M --> N[Fix Issues]
    N --> G
    
    L --> O[üìä Continuous Monitoring]
```

---

## üéõÔ∏è Configura√ß√£o de Deployment por Ambiente

### üîß Matriz de Configura√ß√£o

```mermaid
graph TB
    subgraph "üéöÔ∏è CONFIGURA√á√ïES"
        A[Environment Variables]
        B[Resource Limits]
        C[Network Configuration]
        D[Volume Mounts]
        E[Health Checks]
    end
    
    subgraph "üß™ DEVELOPMENT"
        A --> A1[DEBUG=true<br/>LOG_LEVEL=debug<br/>PROFILE=dev]
        B --> B1[CPU: unlimited<br/>Memory: unlimited<br/>Minimal constraints]
        C --> C1[Bridge network<br/>Port mapping<br/>Host networking]
        D --> D1[Local volumes<br/>Hot reload<br/>Source mounts]
        E --> E1[Basic checks<br/>30s intervals<br/>Simple endpoints]
    end
    
    subgraph "üîß TESTING"
        A --> A2[DEBUG=false<br/>LOG_LEVEL=info<br/>PROFILE=test]
        B --> B2[CPU: 1 core<br/>Memory: 512MB<br/>Strict limits]
        C --> C2[Isolated network<br/>Internal communication<br/>No host access]
        D --> D2[Named volumes<br/>Persistent data<br/>Test fixtures]
        E --> E2[Comprehensive checks<br/>15s intervals<br/>Deep health validation]
    end
    
    subgraph "üìà STAGING"
        A --> A3[DEBUG=false<br/>LOG_LEVEL=warn<br/>PROFILE=staging]
        B --> B3[CPU: 2 cores<br/>Memory: 1GB<br/>Production-like]
        C --> C3[Production network<br/>Load balancing<br/>Service discovery]
        D --> D3[Persistent volumes<br/>Backup enabled<br/>Data replication]
        E --> E3[Production checks<br/>10s intervals<br/>Full monitoring]
    end
    
    subgraph "üè≠ PRODUCTION"
        A --> A4[DEBUG=false<br/>LOG_LEVEL=error<br/>PROFILE=prod]
        B --> B4[CPU: 4+ cores<br/>Memory: 2GB+<br/>High limits]
        C --> C4[HA networking<br/>Multiple subnets<br/>Security groups]
        D --> D4[Replicated storage<br/>Automated backup<br/>Disaster recovery]
        E --> E4[Critical checks<br/>5s intervals<br/>Advanced alerting]
    end
    
    style A1 fill:#e3f2fd
    style A2 fill:#e8f5e8
    style A3 fill:#fff3e0
    style A4 fill:#fce4ec
```

---

## üöÄ Processo de CI/CD Pipeline

```mermaid
flowchart LR
    subgraph "üë®‚Äçüíª DEVELOPMENT"
        A[Code Changes] --> B[Local Testing]
        B --> C[Git Commit]
        C --> D[Push to Feature Branch]
    end
    
    subgraph "üîÑ CONTINUOUS INTEGRATION"
        D --> E[GitHub Actions Trigger]
        E --> F[Build Docker Images]
        F --> G[Run Unit Tests]
        G --> H[Security Scan]
        H --> I[Integration Tests]
    end
    
    subgraph "üìã CODE REVIEW"
        I --> J[Create Pull Request]
        J --> K[Code Review]
        K --> L[Approval Required]
        L --> M[Merge to Develop]
    end
    
    subgraph "üé≠ STAGING DEPLOYMENT"
        M --> N[Auto-deploy Staging]
        N --> O[Run E2E Tests]
        O --> P[Performance Tests]
        P --> Q[User Acceptance Tests]
    end
    
    subgraph "üè∑Ô∏è RELEASE"
        Q --> R[Create Release Tag]
        R --> S[Generate Release Notes]
        S --> T[Deploy to Production]
    end
    
    subgraph "üè≠ PRODUCTION"
        T --> U[Blue-Green Deployment]
        U --> V[Health Validation]
        V --> W[Traffic Switch]
        W --> X[Monitor & Alert]
    end
    
    style A fill:#e3f2fd
    style E fill:#e8f5e8
    style J fill:#fff3e0
    style N fill:#f3e5f5
    style R fill:#fce4ec
    style T fill:#ffebee
```

---

## üìä Monitoramento de Deployment

### üîç Health Check Sequence

```mermaid
sequenceDiagram
    participant Deploy as üöÄ Deployment
    participant Container as üì¶ Container
    participant Health as üè• Health Check
    participant Monitor as üìä Monitoring
    participant Alert as üö® Alerting
    
    Deploy->>Container: Start container
    Container->>Container: Initialize application
    
    loop Health Check Cycle
        Health->>Container: GET /actuator/health
        Container->>Health: Response + Status
        Health->>Monitor: Record metrics
        
        alt Healthy Status
            Monitor->>Monitor: ‚úÖ Update dashboard
        else Unhealthy Status
            Monitor->>Alert: üö® Trigger alert
            Alert->>Deploy: üìß Notify operations team
        end
    end
    
    Note over Health,Monitor: Continuous monitoring<br/>every 10-30 seconds
```

### üìà Metrics Collection Flow

```mermaid
graph TD
    A[üöÄ Application] --> B[üìä Micrometer]
    B --> C[üìà Prometheus]
    C --> D[üìä Grafana Dashboard]
    
    A --> E[üìã Application Logs]
    E --> F[üìÅ Elasticsearch]
    F --> G[üîç Kibana]
    
    A --> H[üè• Health Endpoints]
    H --> I[üîç Health Checks]
    I --> J[üö® Alert Manager]
    
    C --> K[üìä Time Series DB]
    K --> L[üìà Historical Analysis]
    
    J --> M[üìß Email Alerts]
    J --> N[üì± Slack Notifications]
    J --> O[üö® PagerDuty]
    
    style A fill:#e3f2fd
    style C fill:#e8f5e8
    style F fill:#fff3e0
    style J fill:#fce4ec
```

---

## üõ°Ô∏è Estrat√©gias de Rollback

```mermaid
flowchart TD
    A[üö® Deployment Issue Detected] --> B{Issue Severity}
    
    B -->|üü° Low| C[Minor Issue]
    B -->|üü† Medium| D[Service Degradation]  
    B -->|üî¥ High| E[Critical Failure]
    B -->|‚ö´ Critical| F[System Outage]
    
    C --> C1[Hot Fix Deployment]
    C1 --> C2[Patch Current Version]
    C2 --> C3[Validate Fix]
    
    D --> D1[Partial Rollback]
    D1 --> D2[Rollback Affected Services]
    D2 --> D3[Maintain Stable Services]
    
    E --> E1[Quick Rollback]
    E1 --> E2[Previous Stable Version]
    E2 --> E3[Emergency Recovery]
    
    F --> F1[Full System Rollback]
    F1 --> F2[Complete Previous State]
    F2 --> F3[Disaster Recovery Mode]
    
    C3 --> G[‚úÖ Resolution Confirmed]
    D3 --> G
    E3 --> G
    F3 --> G
    
    G --> H[üìä Post-Mortem Analysis]
    H --> I[üìã Update Runbooks]
    I --> J[üîÑ Improve Process]
    
    style E fill:#ffcdd2
    style F fill:#d32f2f,color:#fff
    style G fill:#c8e6c9
```

---

## üìã Deployment Checklist Template

### ‚úÖ Pre-Deployment Verification

```mermaid
graph LR
    A[üìã Pre-Deploy Checklist] --> B[Code Quality]
    B --> B1[‚úÖ Tests Passing]
    B --> B2[‚úÖ Code Review Complete]
    B --> B3[‚úÖ Security Scan Clear]
    
    A --> C[Environment Readiness]
    C --> C1[‚úÖ Infrastructure Available]
    C --> C2[‚úÖ Dependencies Updated]
    C --> C3[‚úÖ Configurations Valid]
    
    A --> D[Team Coordination]
    D --> D1[‚úÖ Deployment Window Scheduled]
    D --> D2[‚úÖ Team Notified]
    D --> D3[‚úÖ Rollback Plan Ready]
    
    style B1 fill:#c8e6c9
    style B2 fill:#c8e6c9
    style B3 fill:#c8e6c9
    style C1 fill:#e1f5fe
    style C2 fill:#e1f5fe
    style C3 fill:#e1f5fe
    style D1 fill:#fff3e0
    style D2 fill:#fff3e0
    style D3 fill:#fff3e0
```

---

*Este documento apresenta todas as estrat√©gias e sequ√™ncias de deployment implementadas no projeto KBNT Kafka Logs, servindo como guia completo para opera√ß√µes de deployment em todos os ambientes.*
