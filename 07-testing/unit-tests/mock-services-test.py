#!/usr/bin/env python3
"""
Aplica√ß√£o Simplificada com Port Assignment + Teste 10K
Usa apenas endpoints mock/simple sem Docker para teste de 10.000 requisi√ß√µes
"""

import os
import sys
import time
import json
import subprocess
import requests
import threading
from datetime import datetime
from pathlib import Path
from http.server import HTTPServer, BaseHTTPRequestHandler
import socketserver

class SimpleApplicationServer:
    def __init__(self, workspace_root):
        self.workspace_root = Path(workspace_root)
        self.servers = {}
        self.health_status = {}
        
    def create_mock_service(self, port, service_name):
        """Cria um servi√ßo mock simples"""
        
        class MockServiceHandler(BaseHTTPRequestHandler):
            def do_GET(self):
                if self.path in ['/actuator/health', '/health']:
                    self.send_response(200)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    response = {
                        'status': 'UP',
                        'service': service_name,
                        'port': port,
                        'timestamp': datetime.now().isoformat()
                    }
                    self.wfile.write(json.dumps(response).encode())
                elif self.path.startswith('/api/v1/'):
                    self.send_response(200)
                    self.send_header('Content-type', 'application/json')
                    self.end_headers()
                    response = {
                        'service': service_name,
                        'endpoint': self.path,
                        'status': 'OK',
                        'data': f"Response from {service_name}",
                        'timestamp': datetime.now().isoformat()
                    }
                    self.wfile.write(json.dumps(response).encode())
                else:
                    self.send_response(404)
                    self.end_headers()
                    
            def log_message(self, format, *args):
                pass  # Silencia logs do servidor
        
        return MockServiceHandler
    
    def start_service(self, port, service_name):
        """Inicia um servi√ßo mock"""
        try:
            handler_class = self.create_mock_service(port, service_name)
            server = HTTPServer(('localhost', port), handler_class)
            
            def run_server():
                print(f"‚úÖ {service_name} mock iniciado na porta {port}")
                server.serve_forever()
            
            import threading
            thread = threading.Thread(target=run_server, daemon=True)
            thread.start()
            
            self.servers[service_name] = {
                'server': server,
                'port': port,
                'thread': thread
            }
            
            # Aguarda um pouco para o servidor estabilizar
            time.sleep(1)
            
            # Verifica se est√° respondendo
            try:
                response = requests.get(f"http://localhost:{port}/actuator/health", timeout=2)
                if response.status_code == 200:
                    self.health_status[service_name] = 'healthy'
                    return True
            except:
                pass
            
            self.health_status[service_name] = 'unhealthy'
            return False
            
        except Exception as e:
            print(f"‚ùå Erro ao iniciar {service_name}: {e}")
            return False
    
    def stop_all_services(self):
        """Para todos os servi√ßos"""
        print("üõë Parando todos os servi√ßos mock...")
        for service_name, service_info in self.servers.items():
            try:
                service_info['server'].shutdown()
                print(f"‚úÖ {service_name} parado")
            except:
                pass

def perform_high_volume_load_test(base_url, num_requests=10000):
    """Executa teste de carga de alto volume com 10.000 requisi√ß√µes"""
    print(f"\nüéØ TESTE DE CARGA DE ALTO VOLUME - {num_requests} REQUISI√á√ïES")
    print("=" * 60)
    
    # M√∫ltiplos endpoints para simular carga real
    test_endpoints = [
        "/actuator/health",
        "/api/v1/virtual-stock/products",
        "/api/v1/virtual-stock/status",
        "/api/v1/logs/recent",
        "/api/v1/logs/status",
        "/api/v1/analytics/summary",
        "/api/v1/analytics/metrics"
    ]
    
    results = {
        'test_config': {
            'total_requests': num_requests,
            'base_url': base_url,
            'test_start': datetime.now().isoformat(),
            'endpoints': test_endpoints
        },
        'performance_metrics': {
            'successful_requests': 0,
            'failed_requests': 0,
            'response_times': [],
            'errors': [],
            'status_codes': {},
            'endpoint_performance': {ep: {'success': 0, 'failed': 0, 'total_time': 0} for ep in test_endpoints}
        }
    }
    
    # Lock para thread safety
    results_lock = threading.Lock()
    start_test_time = time.time()
    
    def execute_request(request_id):
        # Seleciona endpoint de forma balanceada
        import random
        endpoint = random.choice(test_endpoints)
        url = f"{base_url}{endpoint}"
        
        try:
            request_start = time.time()
            response = requests.get(url, timeout=10)
            request_end = time.time()
            
            response_time = (request_end - request_start) * 1000  # milliseconds
            
            with results_lock:
                # Atualiza m√©tricas globais
                if response.status_code == 200:
                    results['performance_metrics']['successful_requests'] += 1
                    results['performance_metrics']['response_times'].append(response_time)
                    
                    # Atualiza m√©tricas por endpoint
                    results['performance_metrics']['endpoint_performance'][endpoint]['success'] += 1
                    results['performance_metrics']['endpoint_performance'][endpoint]['total_time'] += response_time
                else:
                    results['performance_metrics']['failed_requests'] += 1
                    results['performance_metrics']['endpoint_performance'][endpoint]['failed'] += 1
                    results['performance_metrics']['errors'].append(
                        f"Request {request_id} to {endpoint}: HTTP {response.status_code}"
                    )
                
                # Registra c√≥digo de status
                status_code = response.status_code
                if status_code not in results['performance_metrics']['status_codes']:
                    results['performance_metrics']['status_codes'][status_code] = 0
                results['performance_metrics']['status_codes'][status_code] += 1
                
        except Exception as e:
            with results_lock:
                results['performance_metrics']['failed_requests'] += 1
                results['performance_metrics']['endpoint_performance'][endpoint]['failed'] += 1
                results['performance_metrics']['errors'].append(
                    f"Request {request_id} to {endpoint}: {str(e)}"
                )
    
    # Execu√ß√£o em batches com controle de concorr√™ncia
    batch_size = 50
    max_concurrent_threads = 100
    
    print("üöÄ Iniciando execu√ß√£o de requisi√ß√µes em lotes...")
    
    for batch_start in range(0, num_requests, batch_size):
        batch_end = min(batch_start + batch_size, num_requests)
        batch_threads = []
        
        # Controla n√∫mero de threads concorrentes
        for i in range(batch_start, batch_end):
            thread = threading.Thread(target=execute_request, args=(i,))
            batch_threads.append(thread)
            thread.start()
            
            # Limita concorr√™ncia
            if len(batch_threads) >= max_concurrent_threads:
                for t in batch_threads:
                    t.join()
                batch_threads = []
        
        # Aguarda threads restantes do batch
        for thread in batch_threads:
            thread.join()
        
        # Relat√≥rio de progresso
        completed = batch_end
        progress = (completed / num_requests) * 100
        elapsed_time = time.time() - start_test_time
        
        with results_lock:
            current_success_rate = (results['performance_metrics']['successful_requests'] / completed) * 100
            avg_response_time = (
                sum(results['performance_metrics']['response_times']) / 
                len(results['performance_metrics']['response_times'])
            ) if results['performance_metrics']['response_times'] else 0
        
        print(f"Progress: {completed}/{num_requests} ({progress:.1f}%) | "
              f"Sucesso: {current_success_rate:.1f}% | "
              f"Tempo m√©dio: {avg_response_time:.1f}ms | "
              f"Elapsed: {elapsed_time:.1f}s")
        
        # Pequena pausa para n√£o sobrecarregar
        time.sleep(0.2)
    
    # Finaliza medi√ß√µes
    total_test_time = time.time() - start_test_time
    results['test_config']['test_end'] = datetime.now().isoformat()
    results['test_config']['total_duration_seconds'] = total_test_time
    
    # Calcula estat√≠sticas avan√ßadas
    if results['performance_metrics']['response_times']:
        times = sorted(results['performance_metrics']['response_times'])
        
        results['performance_metrics']['statistics'] = {
            'avg_response_time': sum(times) / len(times),
            'min_response_time': min(times),
            'max_response_time': max(times),
            'median_response_time': times[len(times) // 2],
            'p90_response_time': times[int(len(times) * 0.9)],
            'p95_response_time': times[int(len(times) * 0.95)],
            'p99_response_time': times[int(len(times) * 0.99)],
            'total_requests_per_second': num_requests / total_test_time
        }
        
        # Calcula estat√≠sticas por endpoint
        for endpoint, metrics in results['performance_metrics']['endpoint_performance'].items():
            total_endpoint_requests = metrics['success'] + metrics['failed']
            if total_endpoint_requests > 0 and metrics['success'] > 0:
                metrics['avg_response_time'] = metrics['total_time'] / metrics['success']
                metrics['success_rate'] = (metrics['success'] / total_endpoint_requests) * 100
    
    return results

def main():
    workspace_root = Path.cwd()
    app_server = SimpleApplicationServer(workspace_root)
    
    print("üöÄ APLICA√á√ÉO SIMPLIFICADA + TESTE DE 10.000 REQUISI√á√ïES")
    print("=" * 70)
    print("üìù Usando servi√ßos mock para simular microservi√ßos reais")
    
    try:
        # 1. Configurar e iniciar servi√ßos mock
        services_config = {
            'api-gateway': 8080,
            'virtual-stock-service': 8081,
            'log-producer-service': 8082,
            'log-analytics-service': 8083
        }
        
        print("\nüèóÔ∏è  Iniciando servi√ßos mock...")
        healthy_services = []
        
        for service_name, port in services_config.items():
            if app_server.start_service(port, service_name):
                healthy_services.append(service_name)
            else:
                print(f"‚ö†Ô∏è  Falha ao iniciar {service_name}")
        
        if not healthy_services:
            print("‚ùå Nenhum servi√ßo foi iniciado com sucesso")
            return
        
        print(f"‚úÖ {len(healthy_services)} servi√ßos iniciados: {', '.join(healthy_services)}")
        
        # 2. Aguardar estabiliza√ß√£o
        print("\n‚è∞ Aguardando estabiliza√ß√£o...")
        time.sleep(5)
        
        # 3. Executar teste de carga de alto volume
        base_url = "http://localhost:8080"
        print(f"\nüéØ Iniciando teste contra {base_url}")
        
        test_results = perform_high_volume_load_test(base_url, 10000)
        
        # 4. Salvar resultados detalhados
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = f"high_volume_test_results_{timestamp}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(test_results, f, indent=2, ensure_ascii=False)
        
        # 5. Exibir relat√≥rio de resultados
        print("\nüìä RELAT√ìRIO DE TESTE DE ALTO VOLUME - 10.000 REQUISI√á√ïES")
        print("=" * 70)
        
        config = test_results['test_config']
        metrics = test_results['performance_metrics']
        
        print(f"üïí Dura√ß√£o total: {config['total_duration_seconds']:.2f} segundos")
        print(f"üìä Total de requisi√ß√µes: {config['total_requests']}")
        print(f"‚úÖ Requisi√ß√µes bem-sucedidas: {metrics['successful_requests']}")
        print(f"‚ùå Requisi√ß√µes falhadas: {metrics['failed_requests']}")
        
        success_rate = (metrics['successful_requests'] / config['total_requests']) * 100
        print(f"üìà Taxa de sucesso geral: {success_rate:.2f}%")
        
        if 'statistics' in metrics:
            stats = metrics['statistics']
            print(f"\n‚è±Ô∏è  ESTAT√çSTICAS DE PERFORMANCE:")
            print(f"   Requisi√ß√µes por segundo: {stats['total_requests_per_second']:.2f}")
            print(f"   Tempo de resposta m√©dio: {stats['avg_response_time']:.2f}ms")
            print(f"   Tempo m√≠nimo: {stats['min_response_time']:.2f}ms")
            print(f"   Tempo m√°ximo: {stats['max_response_time']:.2f}ms")
            print(f"   Mediana (P50): {stats['median_response_time']:.2f}ms")
            print(f"   P90: {stats['p90_response_time']:.2f}ms")
            print(f"   P95: {stats['p95_response_time']:.2f}ms")
            print(f"   P99: {stats['p99_response_time']:.2f}ms")
        
        print(f"\nüìã C√ìDIGOS DE STATUS HTTP:")
        for status_code, count in metrics['status_codes'].items():
            percentage = (count / config['total_requests']) * 100
            print(f"   HTTP {status_code}: {count} ({percentage:.1f}%)")
        
        print(f"\nüéØ PERFORMANCE POR ENDPOINT:")
        for endpoint, ep_metrics in metrics['endpoint_performance'].items():
            total = ep_metrics['success'] + ep_metrics['failed']
            if total > 0:
                avg_time = ep_metrics.get('avg_response_time', 0)
                success_pct = ep_metrics.get('success_rate', 0)
                print(f"   {endpoint}: {ep_metrics['success']}/{total} "
                      f"({success_pct:.1f}% sucesso, {avg_time:.1f}ms m√©dio)")
        
        print(f"\nüìÑ Resultados detalhados salvos em: {results_file}")
        
        # 6. Avalia√ß√£o de performance
        if success_rate >= 99:
            print("\nüéâ PERFORMANCE EXCEPCIONAL! Taxa de sucesso >= 99%")
        elif success_rate >= 95:
            print("\nüåü EXCELENTE PERFORMANCE! Taxa de sucesso >= 95%")
        elif success_rate >= 90:
            print("\nüëç BOA PERFORMANCE! Taxa de sucesso >= 90%")
        elif success_rate >= 80:
            print("\n‚ö†Ô∏è  PERFORMANCE ACEIT√ÅVEL! Taxa de sucesso >= 80%")
        else:
            print("\nüî¥ PERFORMANCE BAIXA! Requer investiga√ß√£o.")
        
        # Mostra alguns erros se houver
        if metrics['errors'] and len(metrics['errors']) <= 10:
            print(f"\n‚ö†Ô∏è  EXEMPLOS DE ERROS ({len(metrics['errors'])} total):")
            for error in metrics['errors'][:5]:
                print(f"   {error}")
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Teste interrompido pelo usu√°rio")
    except Exception as e:
        print(f"\n‚ùå Erro durante execu√ß√£o: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # Para todos os servi√ßos
        app_server.stop_all_services()
        
        # Salva relat√≥rio de execu√ß√£o
        execution_report = {
            'timestamp': datetime.now().isoformat(),
            'execution_type': 'simple_mock_services',
            'services_started': list(app_server.servers.keys()),
            'health_status': app_server.health_status
        }
        
        execution_file = f"simple_execution_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(execution_file, 'w', encoding='utf-8') as f:
            json.dump(execution_report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìÑ Relat√≥rio de execu√ß√£o salvo em: {execution_file}")

if __name__ == "__main__":
    main()
