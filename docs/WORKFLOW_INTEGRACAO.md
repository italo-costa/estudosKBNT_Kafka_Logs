# üîÑ Workflow de Fluxo de Integra√ß√£o - Tr√°fego de Mensagem JSON

Este documento detalha o fluxo completo de uma mensagem JSON atrav√©s do sistema de microservi√ßos + AMQ Streams, desde a recep√ß√£o HTTP at√© o processamento final.

## üìä Vis√£o Geral do Fluxo

```mermaid
sequenceDiagram
    participant Cliente as Cliente HTTP
    participant Gateway as API Gateway<br/>(Port 8080)
    participant ProducerMS as Microservi√ßo A<br/>Log Producer<br/>(Port 8081)
    participant AMQ as AMQ Streams<br/>Red Hat Kafka
    participant Topic as T√≥picos Kafka<br/>(application-logs<br/>error-logs<br/>audit-logs)
    participant ConsumerMS as Microservi√ßo B<br/>Log Consumer<br/>(Port 8082)
    participant ExternalAPI as API Externa<br/>External Service<br/>(HTTPS)
    participant Analytics as Microservi√ßo C<br/>Log Analytics<br/>(Port 8083)

    Note over Cliente,Analytics: FASE 1: Recep√ß√£o da Mensagem HTTP
    Cliente->>Gateway: POST /api/v1/logs<br/>Content-Type: application/json<br/>Body: LogEntry JSON
    Gateway->>ProducerMS: Route to Producer Service<br/>POST /api/v1/logs
    
    Note over ProducerMS: 1.1 Microservi√ßo A recebe mensagem HTTP
    ProducerMS->>ProducerMS: Log: "Received log entry for service: X, level: Y"
    ProducerMS->>ProducerMS: Validate JSON payload
    ProducerMS->>ProducerMS: Set timestamp if null
    ProducerMS->>ProducerMS: Route message based on log level
    
    Note over ProducerMS,AMQ: 1.2 Publica√ß√£o no AMQ Streams
    ProducerMS->>AMQ: KafkaTemplate.send(topic, key, logEntry)
    ProducerMS->>ProducerMS: Log: "Sending log to topic 'X' with key 'Y'"
    AMQ->>ProducerMS: SendResult (partition, offset)
    ProducerMS->>ProducerMS: Log: "Log sent successfully to partition X offset Y"
    ProducerMS->>Cliente: HTTP 202 Accepted<br/>{"status": "accepted", "message": "queued"}

    Note over Topic: 2. T√≥pico AMQ Streams recebe mensagem
    AMQ->>Topic: Store message in topic partition
    Topic->>Topic: Message stored with offset
    Note over Topic: ‚úÖ Log da mensagem armazenado no t√≥pico
    
    Note over ConsumerMS: 3. Microservi√ßo B consome mensagem
    Topic->>ConsumerMS: @KafkaListener triggers
    ConsumerMS->>ConsumerMS: Log: "Processing message from topic X"
    ConsumerMS->>ConsumerMS: Log: "Received LogEntry: service=Y, level=Z"
    ConsumerMS->>ExternalAPI: HTTP POST to External API
    ExternalAPI->>ConsumerMS: API Response (200 OK)
    ConsumerMS->>ConsumerMS: Log: "Message sent to external API successfully"
    
    Note over Analytics: Processamento Analytics (Opcional)
    ExternalAPI->>Analytics: External system may feed analytics
    Analytics->>Analytics: Generate metrics and analytics
```

---

## üîç **FASE 1: Microservi√ßo A - Recep√ß√£o HTTP**

### **1.1 Recep√ß√£o da Mensagem HTTP**

**Endpoint:** `POST /api/v1/logs`  
**Content-Type:** `application/json`

#### **Exemplo de Mensagem JSON Recebida:**
```json
{
    "service": "user-service",
    "level": "INFO",
    "message": "User authentication successful",
    "timestamp": "2025-08-29T10:30:00.000Z",
    "host": "app-server-01",
    "environment": "production",
    "requestId": "req-12345",
    "userId": "user-789",
    "httpMethod": "POST",
    "endpoint": "/api/auth/login",
    "statusCode": 200,
    "responseTimeMs": 150,
    "metadata": {
        "userAgent": "Mozilla/5.0...",
        "clientIp": "192.168.1.100"
    }
}
```

#### **C√≥digo do Microservi√ßo A (Producer):**
```java
@PostMapping
public ResponseEntity<Map<String, Object>> sendLog(@Valid @RequestBody LogEntry logEntry) {
    // üîç LOG 1.1: Registro da mensagem recebida
    log.info("‚úÖ [HTTP_RECEIVED] Service: {}, Level: {}, Message: {}", 
            logEntry.getService(), 
            logEntry.getLevel(), 
            logEntry.getMessage());
    
    log.info("üìù [REQUEST_DETAILS] RequestId: {}, Host: {}, Timestamp: {}", 
            logEntry.getRequestId(),
            logEntry.getHost(),
            logEntry.getTimestamp());
    
    // Valida√ß√£o e processamento
    if (logEntry.getTimestamp() == null) {
        logEntry.setTimestamp(Instant.now());
        log.debug("üïê [TIMESTAMP_SET] Auto-generated timestamp: {}", logEntry.getTimestamp());
    }
```

### **1.2 Roteamento e Publica√ß√£o no AMQ Streams**

#### **L√≥gica de Roteamento por N√≠vel:**
```java
try {
    CompletableFuture<SendResult<String, LogEntry>> future;
    String targetTopic;
    
    // Roteamento baseado no n√≠vel do log
    switch (logEntry.getLevel().toUpperCase()) {
        case "ERROR", "FATAL":
            targetTopic = errorLogsTopic; // "error-logs"
            future = logProducerService.sendErrorLog(logEntry);
            break;
        case "WARN":
            if (isSecurityRelated(logEntry.getMessage())) {
                targetTopic = auditLogsTopic; // "audit-logs"
                future = logProducerService.sendAuditLog(logEntry);
            } else {
                targetTopic = applicationLogsTopic; // "application-logs"
                future = logProducerService.sendApplicationLog(logEntry);
            }
            break;
        default:
            targetTopic = applicationLogsTopic; // "application-logs"
            future = logProducerService.sendApplicationLog(logEntry);
            break;
    }
    
    // üîç LOG 1.2: Registro da publica√ß√£o no Kafka
    log.info("üì§ [KAFKA_SEND] Topic: {}, Key: {}, Service: {}", 
            targetTopic, 
            logEntry.getService(), 
            logEntry.getService());
    
    log.debug("üéØ [KAFKA_PAYLOAD] Sending to Kafka: {}", 
             objectMapper.writeValueAsString(logEntry));
```

#### **Publica√ß√£o no Kafka (LogProducerService):**
```java
public CompletableFuture<SendResult<String, LogEntry>> sendLog(String topic, LogEntry logEntry) {
    // Usa o servi√ßo como chave para particionamento
    String key = logEntry.getService();
    
    // üîç LOG 1.2.1: Pre-send logging
    log.debug("üöÄ [KAFKA_SENDING] Topic: '{}', Key: '{}', Message: '{}'", 
              topic, key, logEntry.getMessage());
    
    CompletableFuture<SendResult<String, LogEntry>> future = 
        kafkaTemplate.send(topic, key, logEntry);
        
    future.whenComplete((result, ex) -> {
        if (ex == null) {
            // üîç LOG 1.2.2: Success logging
            log.info("‚úÖ [KAFKA_SUCCESS] Topic: '{}', Partition: {}, Offset: {}, Key: '{}'", 
                     result.getRecordMetadata().topic(),
                     result.getRecordMetadata().partition(),
                     result.getRecordMetadata().offset(),
                     key);
        } else {
            // üîç LOG 1.2.3: Error logging
            log.error("‚ùå [KAFKA_ERROR] Failed to send to topic '{}': {}", 
                     topic, ex.getMessage(), ex);
        }
    });
    
    return future;
}
```

#### **Resposta HTTP para o Cliente:**
```java
Map<String, Object> response = new HashMap<>();
response.put("status", "accepted");
response.put("message", "Log entry queued for processing");
response.put("timestamp", Instant.now());
response.put("logLevel", logEntry.getLevel());
response.put("service", logEntry.getService());
response.put("targetTopic", targetTopic);

// üîç LOG 1.3: Resposta enviada
log.info("üìÆ [HTTP_RESPONSE] Status: 202 Accepted, Service: {}, Topic: {}", 
        logEntry.getService(), targetTopic);

return ResponseEntity.accepted().body(response);
```

---

## üéØ **FASE 2: AMQ Streams - Recep√ß√£o e Armazenamento**

### **2.1 T√≥pico Recebe a Mensagem**

**No cluster AMQ Streams da Red Hat:**

```bash
# Configura√ß√£o do t√≥pico (exemplo: application-logs)
Topic: application-logs
Partitions: 3
Replication Factor: 3
Retention: 7 days
```

#### **Log no AMQ Streams:**
```bash
[2025-08-29 10:30:00.150] INFO [kafka.server.BrokerTopicMetrics] 
Topic=application-logs Partition=1 Message received:
  Key: user-service
  Offset: 12345
  Size: 856 bytes
  Headers: {content-type=application/json}

[2025-08-29 10:30:00.151] DEBUG [kafka.log.Log] 
Topic=application-logs Partition=1 Offset=12345 
‚úÖ Message successfully appended to log segment
```

### **2.2 Verifica√ß√£o de Log da Mensagem no AMQ Streams**

**‚úÖ Sim, √© poss√≠vel realizar log da mensagem no AMQ Streams:**

1. **Logs do Broker Kafka:**
   - Logs de recep√ß√£o de mensagem
   - Logs de particionamento
   - Logs de replica√ß√£o

2. **Metrics do AMQ Streams:**
   - Message rate per topic
   - Partition distribution
   - Consumer lag monitoring

3. **Strimzi Operator Logs:**
   ```bash
   kubectl logs -f deployment/strimzi-cluster-operator -n kafka
   ```

---

## üì• **FASE 3: Microservi√ßo B - Consumo da Mensagem**

### **3.1 Consumer Kafka Listener**

```java
@Component
@Slf4j
public class LogConsumerService {

    @Autowired
    private ExternalApiClient externalApiClient;

    @KafkaListener(topics = "application-logs", groupId = "log-consumer-group")
    public void processApplicationLog(LogEntry logEntry) {
        // üîç LOG 3.1: Mensagem recebida do Kafka
        log.info("üì• [KAFKA_CONSUMED] Topic: application-logs, Service: {}, Level: {}", 
                logEntry.getService(), 
                logEntry.getLevel());
        
        log.info("üìù [MESSAGE_DETAILS] RequestId: {}, Message: '{}', Timestamp: {}", 
                logEntry.getRequestId(),
                logEntry.getMessage(),
                logEntry.getTimestamp());
        
        try {
            // Processar e enviar para API externa
            ExternalApiRequest apiRequest = mapToExternalRequest(logEntry);
            ExternalApiResponse response = externalApiClient.sendLogData(apiRequest);
            
            // üîç LOG 3.2: Sucesso no envio para API externa
            log.info("‚úÖ [API_SENT] RequestId: {}, Service: {}, External API Response: {}", 
                    logEntry.getRequestId(), 
                    logEntry.getService(),
                    response.getStatus());
            
            // Update metrics
            updateProcessingMetrics(logEntry);
            
        } catch (Exception e) {
            // üîç LOG 3.3: Erro no processamento
            log.error("‚ùå [API_ERROR] Failed to send log to external API for service {}: {}", 
                     logEntry.getService(), e.getMessage(), e);
            
            // Send to DLQ (Dead Letter Queue) if configured
            handleProcessingError(logEntry, e);
        }
    }

    @KafkaListener(topics = "error-logs", groupId = "log-consumer-group")
    public void processErrorLog(LogEntry logEntry) {
        // üîç LOG 3.4: Error log espec√≠fico
        log.warn("üö® [ERROR_LOG_CONSUMED] Service: {}, Error: {}", 
                logEntry.getService(), 
                logEntry.getMessage());
        
        // Processamento espec√≠fico para logs de erro - envio priorit√°rio para API
        processHighPriorityLog(logEntry);
    }

    @KafkaListener(topics = "audit-logs", groupId = "log-consumer-group")
    public void processAuditLog(LogEntry logEntry) {
        // üîç LOG 3.5: Audit log espec√≠fico
        log.info("üîê [AUDIT_LOG_CONSUMED] Service: {}, User: {}, Action: {}", 
                logEntry.getService(), 
                logEntry.getUserId(), 
                logEntry.getMessage());
        
        // Processamento espec√≠fico para auditoria - envio para API de compliance
        processAuditEvent(logEntry);
    }
}
```

### **3.2 Chamada para API Externa**

```java
@Service
@Slf4j 
public class ExternalApiClient {

    @Autowired
    private RestTemplate restTemplate;
    
    @Value("${external.api.logs.endpoint}")
    private String externalApiEndpoint;
    
    @Value("${external.api.timeout:10000}")
    private int timeout;

    public ExternalApiResponse sendLogData(ExternalApiRequest request) {
        // üîç LOG 3.6: Preparando chamada para API externa
        log.debug("üåê [API_CALLING] Sending log data to external API: {}", 
                 externalApiEndpoint);
        
        log.debug("üéØ [API_PAYLOAD] RequestId: {}, Service: {}, Level: {}", 
                 request.getRequestId(), 
                 request.getService(), 
                 request.getLevel());
        
        try {
            // Headers para a API externa
            HttpHeaders headers = new HttpHeaders();
            headers.setContentType(MediaType.APPLICATION_JSON);
            headers.set("X-Request-ID", request.getRequestId());
            headers.set("X-Source-Service", "log-consumer-service");
            
            HttpEntity<ExternalApiRequest> entity = new HttpEntity<>(request, headers);
            
            // Chamada HTTP para API externa
            ResponseEntity<ExternalApiResponse> response = restTemplate.exchange(
                externalApiEndpoint,
                HttpMethod.POST,
                entity,
                ExternalApiResponse.class
            );
            
            // üîç LOG 3.7: Sucesso na chamada API
            log.info("‚úÖ [API_SUCCESS] External API responded with status: {}, ResponseTime: {}ms", 
                    response.getStatusCode(),
                    response.getBody().getProcessingTime());
            
            return response.getBody();
            
        } catch (HttpClientErrorException e) {
            // üîç LOG 3.8: Erro 4xx da API externa
            log.error("‚ùå [API_CLIENT_ERROR] External API client error {}: {}", 
                     e.getStatusCode(), e.getResponseBodyAsString());
            throw new ExternalApiException("Client error calling external API", e);
            
        } catch (HttpServerErrorException e) {
            // üîç LOG 3.9: Erro 5xx da API externa
            log.error("‚ùå [API_SERVER_ERROR] External API server error {}: {}", 
                     e.getStatusCode(), e.getResponseBodyAsString());
            throw new ExternalApiException("Server error calling external API", e);
            
        } catch (ResourceAccessException e) {
            // üîç LOG 3.10: Erro de conectividade
            log.error("‚ùå [API_CONNECTIVITY_ERROR] Failed to connect to external API: {}", 
                     e.getMessage());
            throw new ExternalApiException("Connectivity error with external API", e);
        }
    }
    
    private ExternalApiRequest mapToExternalRequest(LogEntry logEntry) {
        return ExternalApiRequest.builder()
            .requestId(logEntry.getRequestId())
            .service(logEntry.getService())
            .level(logEntry.getLevel())
            .message(logEntry.getMessage())
            .timestamp(logEntry.getTimestamp())
            .host(logEntry.getHost())
            .environment(logEntry.getEnvironment())
            .userId(logEntry.getUserId())
            .httpMethod(logEntry.getHttpMethod())
            .endpoint(logEntry.getEndpoint())
            .statusCode(logEntry.getStatusCode())
            .responseTimeMs(logEntry.getResponseTimeMs())
            .metadata(logEntry.getMetadata())
            .build();
    }
}
```

---

## üìà **Logs Detalhados do Fluxo Completo**

### **Console Logs do Microservi√ßo A (Producer):**
```log
2025-08-29 10:30:00.100 INFO  [http-nio-8081-exec-1] LogController : 
‚úÖ [HTTP_RECEIVED] Service: user-service, Level: INFO, Message: User authentication successful

2025-08-29 10:30:00.102 INFO  [http-nio-8081-exec-1] LogController : 
üìù [REQUEST_DETAILS] RequestId: req-12345, Host: app-server-01, Timestamp: 2025-08-29T10:30:00.000Z

2025-08-29 10:30:00.105 INFO  [http-nio-8081-exec-1] LogController : 
üì§ [KAFKA_SEND] Topic: application-logs, Key: user-service, Service: user-service

2025-08-29 10:30:00.108 DEBUG [kafka-producer-network-thread] LogProducerService : 
üöÄ [KAFKA_SENDING] Topic: 'application-logs', Key: 'user-service', Message: 'User authentication successful'

2025-08-29 10:30:00.125 INFO  [kafka-producer-network-thread] LogProducerService : 
‚úÖ [KAFKA_SUCCESS] Topic: 'application-logs', Partition: 1, Offset: 12345, Key: 'user-service'

2025-08-29 10:30:00.127 INFO  [http-nio-8081-exec-1] LogController : 
üìÆ [HTTP_RESPONSE] Status: 202 Accepted, Service: user-service, Topic: application-logs
```

### **Console Logs do AMQ Streams (Kafka):**
```log
2025-08-29 10:30:00.126 INFO  [kafka-request-handler-1] kafka.server.KafkaApis : 
üì• [BROKER_RECEIVED] Topic: application-logs, Partition: 1, Offset: 12345, Size: 856 bytes

2025-08-29 10:30:00.127 DEBUG [kafka-log-1] kafka.log.Log : 
‚úÖ [LOG_APPENDED] Topic: application-logs, Partition: 1, Offset: 12345, Segment: 00000000000012000.log
```

### **Console Logs do Microservi√ßo B (Consumer):**
```log
2025-08-29 10:30:00.150 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] LogConsumerService : 
üì• [KAFKA_CONSUMED] Topic: application-logs, Service: user-service, Level: INFO

2025-08-29 10:30:00.151 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] LogConsumerService : 
üìù [MESSAGE_DETAILS] RequestId: req-12345, Message: 'User authentication successful', Timestamp: 2025-08-29T10:30:00.000Z

2025-08-29 10:30:00.155 DEBUG [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] ExternalApiClient : 
üåê [API_CALLING] Sending log data to external API: https://external-logs-api.company.com/v1/logs

2025-08-29 10:30:00.158 DEBUG [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] ExternalApiClient : 
üéØ [API_PAYLOAD] RequestId: req-12345, Service: user-service, Level: INFO

2025-08-29 10:30:00.185 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] ExternalApiClient : 
‚úÖ [API_SUCCESS] External API responded with status: 200 OK, ResponseTime: 27ms

2025-08-29 10:30:00.186 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] LogConsumerService : 
‚úÖ [API_SENT] RequestId: req-12345, Service: user-service, External API Response: SUCCESS
```

---

## üéØ **Resumo do Fluxo de Tr√°fego**

| **Fase** | **Componente** | **A√ß√£o** | **Log Key** | **Dados** |
|----------|---------------|----------|-------------|-----------|
| **1.1** | Microservi√ßo A | Recebe HTTP | `HTTP_RECEIVED` | JSON payload |
| **1.2** | Microservi√ßo A | Publica Kafka | `KAFKA_SEND` | Topic + Key + Message |
| **2.1** | AMQ Streams | Armazena | `BROKER_RECEIVED` | Partition + Offset |
| **3.1** | Microservi√ßo B | Consome | `KAFKA_CONSUMED` | Topic + Service |
| **3.2** | Microservi√ßo B | API Externa | `API_SENT` | External API Response |

**‚úÖ Confirma√ß√£o:** Sim, √© poss√≠vel realizar log completo da mensagem em todas as fases, desde a recep√ß√£o HTTP at√© o envio para API externa, incluindo logs no pr√≥prio AMQ Streams!

---

## üîß **Comandos para Monitorar o Fluxo**

### **1. Monitorar Microservi√ßos:**
```bash
# Producer logs
kubectl logs -f deployment/log-producer-service -n microservices

# Consumer logs  
kubectl logs -f deployment/log-consumer-service -n microservices

# Analytics logs
kubectl logs -f deployment/log-analytics-service -n microservices
```

### **2. Monitorar AMQ Streams:**
```bash
# Kafka cluster logs
kubectl logs -f kafka-cluster-kafka-0 -n kafka

# Strimzi operator logs
kubectl logs -f deployment/strimzi-cluster-operator -n kafka

# Topic info
kubectl exec kafka-cluster-kafka-0 -n kafka -- bin/kafka-topics.sh --list --bootstrap-server localhost:9092
```

### **3. Testar o Fluxo Completo:**
```bash
# Enviar log via API
curl -X POST http://localhost:8081/api/v1/logs \
  -H "Content-Type: application/json" \
  -d '{
    "service": "user-service",
    "level": "INFO", 
    "message": "Test message for workflow",
    "requestId": "test-123"
  }'

# Verificar no banco
kubectl exec -it postgres-0 -n microservices -- psql -U loguser -d loganalytics -c "SELECT * FROM log_entries ORDER BY created_at DESC LIMIT 5;"
```

Este workflow garante **rastreabilidade completa** da mensagem JSON desde o HTTP at√© a persist√™ncia final! üéØ
