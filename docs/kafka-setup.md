# Configura√ß√£o do Red Hat AMQ Streams para Logs

## Vis√£o Geral

Este documento explica como configurar o Red Hat AMQ Streams especificamente para processamento de logs em um ambiente de estudos.

## üî¥ Sobre o Red Hat AMQ Streams

O AMQ Streams √© baseado no projeto open-source **Strimzi** e fornece:
- Apache Kafka com suporte enterprise
- Operadores Kubernetes nativos
- Configura√ß√£o declarativa via Custom Resources
- Monitoramento e m√©tricas integradas
- Gest√£o simplificada de clusters Kafka
- **Vers√£o Community gratuita dispon√≠vel**

## üéØ Objetivos

- Configurar AMQ Streams para alta performance com logs
- Otimizar reten√ß√£o e particionamento para dados de log
- Configurar produtores e consumidores eficientes
- Implementar padr√µes de monitoramento
- Utilizar recursos enterprise na vers√£o community

## üìã T√≥picos Recomendados

### 1. application-logs
**Prop√≥sito**: Logs gerais da aplica√ß√£o
```bash
# Criar t√≥pico
kafka-topics --create --topic application-logs \
  --bootstrap-server localhost:9092 \
  --partitions 6 \
  --replication-factor 3 \
  --config retention.ms=604800000 \
  --config segment.ms=86400000 \
  --config compression.type=snappy
```

**Configura√ß√µes**:
- **Parti√ß√µes**: 6 (permite 6 consumidores paralelos)
- **Reten√ß√£o**: 7 dias (604800000 ms)
- **Segmentos**: 1 dia (86400000 ms)
- **Compress√£o**: Snappy (boa para logs)

### 2. error-logs
**Prop√≥sito**: Logs de erro e exce√ß√µes
```bash
kafka-topics --create --topic error-logs \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 3 \
  --config retention.ms=2592000000 \
  --config min.insync.replicas=2
```

**Configura√ß√µes**:
- **Reten√ß√£o**: 30 dias (mais tempo para an√°lise de erros)
- **min.insync.replicas**: 2 (maior durabilidade para erros)

### 3. audit-logs
**Prop√≥sito**: Logs de auditoria e seguran√ßa
```bash
kafka-topics --create --topic audit-logs \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 3 \
  --config retention.ms=-1 \
  --config cleanup.policy=compact
```

**Configura√ß√µes**:
- **Reten√ß√£o**: Infinita (dados de auditoria)
- **Cleanup**: Compact (mant√©m √∫ltimo valor por chave)

## ‚öôÔ∏è Configura√ß√µes do Broker

### server.properties otimizado para logs:

```properties
# Performance para logs
num.network.threads=8
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400

# Configura√ß√µes de log
log.retention.hours=168
log.retention.bytes=1073741824
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000

# Compress√£o padr√£o
compression.type=snappy

# Auto-cria√ß√£o de t√≥picos
auto.create.topics.enable=true
num.partitions=3
default.replication.factor=3
```

## üîß Configura√ß√µes de Produtores

### Para Alta Performance:
```python
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    acks='1',  # Apenas leader confirma
    retries=3,
    batch_size=32768,  # Batches maiores para logs
    linger_ms=10,      # Aguarda 10ms para formar batches
    compression_type='snappy',
    buffer_memory=67108864,  # 64MB buffer
)
```

### Para Alta Durabilidade (logs cr√≠ticos):
```python
producer = KafkaProducer(
    bootstrap_servers=['localhost:9092'],
    acks='all',  # Todas r√©plicas confirmam
    retries=5,
    batch_size=16384,
    linger_ms=5,
    compression_type='gzip',  # Melhor compress√£o
    enable_idempotence=True,
)
```

## üì• Configura√ß√µes de Consumidores

### Consumer Group para Processamento Paralelo:
```python
consumer = KafkaConsumer(
    'application-logs',
    bootstrap_servers=['localhost:9092'],
    group_id='log-processor-group',
    auto_offset_reset='earliest',
    enable_auto_commit=True,
    auto_commit_interval_ms=1000,
    max_poll_records=1000,  # Processa muitos logs por vez
)
```

### Consumer para An√°lise em Tempo Real:
```python
consumer = KafkaConsumer(
    'error-logs',
    bootstrap_servers=['localhost:9092'],
    group_id='realtime-alert-group',
    auto_offset_reset='latest',  # Apenas novos erros
    enable_auto_commit=False,    # Controle manual
    max_poll_interval_ms=30000,
)
```

## üìä Particionamento de Logs

### Por Servi√ßo:
```python
# Usa o nome do servi√ßo como chave
key = log_entry['service']
producer.send('application-logs', key=key, value=log_entry)
```

### Por Severidade:
```python
# Particiona por n√≠vel de log
if log_entry['level'] == 'ERROR':
    producer.send('error-logs', value=log_entry)
else:
    producer.send('application-logs', value=log_entry)
```

### Por Timestamp:
```python
# Para an√°lise temporal
key = log_entry['timestamp'][:10]  # YYYY-MM-DD
producer.send('application-logs', key=key, value=log_entry)
```

## üîç Monitoramento

### M√©tricas Importantes:

1. **Taxa de Produ√ß√£o**:
   - `kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec`

2. **Taxa de Consumo**:
   - `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*`

3. **Lag do Consumidor**:
   - `kafka.consumer:type=consumer-fetch-manager-metrics,name=records-lag-max`

4. **Utiliza√ß√£o de Disco**:
   - Monitorar `/var/lib/kafka/data`

### Comandos de Monitoramento:

```bash
# Ver todos os t√≥picos
kafka-topics --list --bootstrap-server localhost:9092

# Detalhes de um t√≥pico
kafka-topics --describe --topic application-logs --bootstrap-server localhost:9092

# Consumer groups
kafka-consumer-groups --list --bootstrap-server localhost:9092

# Lag de um group
kafka-consumer-groups --describe --group log-processor-group --bootstrap-server localhost:9092
```

## üö® Alertas e Troubleshooting

### Alertas Importantes:

1. **Disk Usage > 80%**
2. **Consumer Lag > 10000**
3. **Error Rate > 5%**
4. **Partition Leader Changes**

### Comandos de Debug:

```bash
# Ver mensagens de um t√≥pico
kafka-console-consumer --topic application-logs --from-beginning --bootstrap-server localhost:9092

# Resetar offset de consumer group
kafka-consumer-groups --reset-offsets --group my-group --topic application-logs --to-earliest --bootstrap-server localhost:9092

# Ver configura√ß√µes de um t√≥pico
kafka-configs --describe --entity-type topics --entity-name application-logs --bootstrap-server localhost:9092
```

## üéØ Pr√≥ximos Passos

1. [Deploy no Kubernetes](kubernetes-deployment.md)
2. [Integra√ß√£o com ELK Stack](elk-integration.md)
3. [Monitoramento com Grafana](monitoring.md)
4. [Padr√µes de Logs](logging-patterns.md)
