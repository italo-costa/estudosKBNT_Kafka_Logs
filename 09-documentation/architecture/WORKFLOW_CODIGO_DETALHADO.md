# üîÑ Workflow Detalhado - Sistema KBNT Log Service

Baseado na an√°lise completa do c√≥digo, aqui est√° o workflow detalhado do sistema com foco nas mensagens e tecnologias utilizadas.

## üìã **Estrutura da Mensagem (LogMessage)**

### **üéØ Modelo Unificado de Dados**
```java
@Data
@Builder
public class LogMessage {
    @NotBlank private String level;          // DEBUG, INFO, WARN, ERROR, FATAL
    @NotBlank private String message;        // Conte√∫do da mensagem
    private String serviceName;              // Nome do servi√ßo origem
    private String category;                 // APPLICATION, ERROR, AUDIT, FINANCIAL
    private LocalDateTime timestamp;         // Timestamp ISO 8601
    private String correlationId;            // ID para rastreamento
    private String userId;                   // ID do usu√°rio (auditoria)
    private String sessionId;                // ID da sess√£o
    private String requestId;                // ID da requisi√ß√£o
    private ExceptionInfo exception;         // Informa√ß√µes de exce√ß√£o
    private Map<String, Object> metadata;   // Metadados adicionais
    private String environment;             // dev, test, prod
    private String version;                 // Vers√£o da aplica√ß√£o
    private String hostname;                // Host/pod de origem
}
```

**üîß Tecnologias de Serializa√ß√£o:**
- **Jackson**: Serializa√ß√£o/deserializa√ß√£o JSON
- **Bean Validation**: Valida√ß√£o com `@NotBlank`, `@NotNull`
- **Lombok**: Redu√ß√£o de boilerplate code
- **Java Time API**: Timestamps precisos com `LocalDateTime`

---

## üöÄ **Etapa 1: Recep√ß√£o de Mensagens**

### **üì° Controller REST Unificado**
```java
@RestController
@RequestMapping("/api/v1/logs")
@ConditionalOnExpression("'${app.processing.modes}'.contains('producer')")
public class UnifiedLogController {
    
    // Endpoints dispon√≠veis:
    // POST /api/v1/logs              -> Roteamento autom√°tico
    // POST /api/v1/logs/application  -> Logs de aplica√ß√£o
    // POST /api/v1/logs/error        -> Logs de erro
    // POST /api/v1/logs/audit        -> Logs de auditoria
    // POST /api/v1/logs/financial    -> Logs financeiros
    // POST /api/v1/logs/batch        -> Processamento em lote
}
```

**üõ†Ô∏è Tecnologias:**
- **Spring Boot 3.2**: Framework web reativo
- **Spring Web MVC**: Controllers REST
- **Bean Validation**: Valida√ß√£o autom√°tica de payloads
- **Micrometer**: M√©tricas com `@Timed`
- **CompletableFuture**: Processamento ass√≠ncrono

**üìù Fluxo de Processamento:**
1. **Recep√ß√£o HTTP**: Cliente envia POST com LogMessage JSON
2. **Valida√ß√£o**: Spring valida campos obrigat√≥rios (`@Valid`)
3. **Header Processing**: Extrai `X-Correlation-ID` se presente
4. **Enriquecimento**: Adiciona metadados automaticamente
5. **Resposta Ass√≠ncrona**: Retorna `CompletableFuture<ResponseEntity>`

---

## ‚öôÔ∏è **Etapa 2: Processamento e Enriquecimento**

### **üîß Unified Log Producer**
```java
@Service
@ConditionalOnExpression("'${app.processing.modes}'.contains('producer')")
public class UnifiedLogProducer {
    
    private void enrichLogMessage(LogMessage logMessage) {
        // Auto-timestamp se n√£o fornecido
        if (logMessage.getTimestamp() == null) {
            logMessage.setTimestamp(LocalDateTime.now());
        }
        
        // UUID para correla√ß√£o se n√£o fornecido
        if (logMessage.getCorrelationId() == null) {
            logMessage.setCorrelationId(UUID.randomUUID().toString());
        }
        
        // Service name padr√£o
        if (logMessage.getServiceName() == null) {
            logMessage.setServiceName("kbnt-log-service");
        }
    }
}
```

**üéØ Algoritmo de Roteamento Inteligente:**
```java
private String determineTargetTopic(LogMessage logMessage) {
    String level = logMessage.getLevel().toUpperCase();
    String category = logMessage.getCategory();
    
    // 1. PRIORIDADE: Logs Financeiros
    if ("FINANCIAL".equalsIgnoreCase(category) || 
        message.contains("transaction") || message.contains("payment")) {
        return financialLogsTopic; // kbnt-financial-logs
    }
    
    // 2. Logs de Auditoria
    if ("AUDIT".equalsIgnoreCase(category) || 
        message.contains("audit") || message.contains("security")) {
        return auditLogsTopic; // kbnt-audit-logs
    }
    
    // 3. Logs de Erro (ERROR/FATAL)
    if ("ERROR".equals(level) || "FATAL".equals(level)) {
        return errorLogsTopic; // kbnt-error-logs
    }
    
    // 4. PADR√ÉO: Logs de Aplica√ß√£o
    return applicationLogsTopic; // kbnt-application-logs
}
```

---

## üèóÔ∏è **Etapa 3: Topics AMQ Streams**

### **üìã Configura√ß√£o Diferenciada por Tipo**

#### **üîπ Application Logs Topic**
```yaml
name: kbnt-application-logs
partitions: 6        # Alto throughput
replicas: 3          # Disponibilidade
retention: 7 days    # Curto prazo
compression: snappy  # Performance
max.message: 1MB     # Mensagens m√©dias
```

#### **üö® Error Logs Topic**
```yaml
name: kbnt-error-logs  
partitions: 4        # Processamento focado
retention: 30 days   # Reten√ß√£o estendida
compression: lz4     # Melhor compress√£o
max.message: 2MB     # Stack traces grandes
min.insync: 2        # Consist√™ncia
```

#### **üîê Audit Logs Topic**
```yaml
name: kbnt-audit-logs
partitions: 3        # Processamento sequencial
retention: 90 days   # Compliance
compression: gzip    # M√°xima compress√£o
segment: 2 hours     # Arquivamento frequente
```

#### **üí∞ Financial Logs Topic**
```yaml
name: kbnt-financial-logs
partitions: 8        # M√°xima paraleliza√ß√£o  
retention: 365 days  # Regulamenta√ß√£o
compression: lz4     # Balance performance/compress√£o
min.insync: 3        # M√°xima consist√™ncia
```

**üõ†Ô∏è Tecnologias AMQ Streams:**
- **Strimzi Operator**: Gerenciamento declarativo do Kafka
- **Kafka CRDs**: Defini√ß√£o de topics via Kubernetes
- **Red Hat AMQ Streams**: Plataforma empresarial Kafka
- **OpenShift/Kubernetes**: Orquestra√ß√£o de containers

---

## üîÑ **Etapa 4: Modos de Execu√ß√£o Configur√°veis**

### **‚öôÔ∏è Processing Mode Configuration**
```java
@Configuration
public class ProcessingModeConfiguration {
    
    @Value("${app.processing.modes:producer,consumer,processor}")
    private String processingModes;
    
    // M√©todos de controle:
    public boolean isProducerModeEnabled()  // REST API ativa
    public boolean isConsumerModeEnabled()  // Kafka consumers ativos  
    public boolean isProcessorModeEnabled() // Business logic ativa
}
```

### **üéõÔ∏è Configura√ß√µes Condicionais**
```java
// Producer Mode - Apenas quando "producer" est√° ativo
@Configuration
@ConditionalOnProperty(value = "app.processing.modes", havingValue = "producer")
class ProducerModeConfiguration { }

// Consumer Mode - Apenas quando "consumer" est√° ativo  
@Configuration
@ConditionalOnProperty(value = "app.processing.modes", havingValue = "consumer")
class ConsumerModeConfiguration { }

// Processor Mode - Apenas quando "processor" est√° ativo
@Configuration
@ConditionalOnProperty(value = "app.processing.modes", havingValue = "processor") 
class ProcessorModeConfiguration { }
```

**üîß Cen√°rios de Deployment:**
```bash
# Cen√°rio 1: Servidor completo
APP_PROCESSING_MODES=producer,consumer,processor

# Cen√°rio 2: Apenas API (scale horizontal)
APP_PROCESSING_MODES=producer

# Cen√°rio 3: Apenas processamento (scale vertical)
APP_PROCESSING_MODES=consumer,processor

# Cen√°rio 4: Worker dedicado
APP_PROCESSING_MODES=processor
```

---

## üìä **Etapa 5: Particionamento e Performance**

### **üéØ Estrat√©gia de Particionamento**
```java
private String generatePartitionKey(LogMessage logMessage) {
    // Chave composta: servi√ßo + n√≠vel
    return String.format("%s-%s", 
        logMessage.getServiceName() != null ? logMessage.getServiceName() : "unknown",
        logMessage.getLevel());
}
```

**üìà Distribui√ß√£o de Carga:**
- **Application Logs**: 6 partitions ‚Üí ~16% cada
- **Error Logs**: 4 partitions ‚Üí 25% cada
- **Audit Logs**: 3 partitions ‚Üí ~33% cada  
- **Financial Logs**: 8 partitions ‚Üí 12.5% each

### **‚ö° Configura√ß√µes de Performance**
```yaml
spring:
  kafka:
    producer:
      acks: all                    # M√°xima durabilidade
      retries: 3                   # Retry autom√°tico
      batch-size: 16384           # 16KB batches
      linger-ms: 10               # Micro-batching
      buffer-memory: 33554432     # 32MB buffer
      compression-type: snappy     # Performance
      enable.idempotence: true     # Exactly-once semantics
      
    consumer:
      group-id: kbnt-log-consumer-group
      auto-offset-reset: earliest  # Processa todas as mensagens
      enable-auto-commit: false    # Controle manual de offsets
      max-poll-records: 500        # Batch processing
      session-timeout-ms: 30000    # Detec√ß√£o de falhas
```

---

## üõ°Ô∏è **Etapa 6: Resili√™ncia e Observabilidade**

### **üîß Circuit Breaker Pattern**
```yaml
app:
  circuit-breaker:
    enabled: true
    failure-rate-threshold: 60    # 60% falhas
    wait-duration-in-open-state: 30s
    sliding-window-size: 10
    minimum-number-of-calls: 5
```

### **üìà M√©tricas Integradas**
```java
@Timed(value = "log.produce", description = "Time taken to produce log messages")
public CompletableFuture<ResponseEntity<Map<String, Object>>> produceLog() {
    // M√©tricas autom√°ticas:
    // - log_produce_duration_seconds
    // - log_produce_total
    // - kafka_producer_messages_sent_total
    // - kafka_consumer_lag_by_partition
}
```

**üè• Health Checks:**
```yaml
management:
  endpoint:
    health:
      show-details: always
      probes:
        enabled: true
  # Endpoints dispon√≠veis:
  # /actuator/health        - Status geral
  # /actuator/health/kafka  - Status Kafka espec√≠fico
  # /actuator/metrics       - M√©tricas Prometheus
  # /actuator/prometheus    - M√©tricas formatted
```

---

## üöÄ **Tecnologias Utilizadas - Stack Completo**

### **üéØ Application Layer**
- **Spring Boot 3.2**: Framework principal
- **Spring Kafka**: Integra√ß√£o Kafka nativa
- **Spring Web**: REST controllers
- **Spring Actuator**: Observabilidade
- **Jackson**: Serializa√ß√£o JSON
- **Bean Validation**: Valida√ß√£o de dados
- **Lombok**: Redu√ß√£o de boilerplate

### **‚ö° Messaging Layer**  
- **Red Hat AMQ Streams**: Kafka empresarial
- **Strimzi Operator**: Gerenciamento declarativo
- **Apache Kafka 3.4**: Message streaming
- **Zookeeper**: Coordena√ß√£o de cluster

### **üèóÔ∏è Infrastructure Layer**
- **Kubernetes/OpenShift**: Orquestra√ß√£o
- **Docker**: Containeriza√ß√£o
- **Helm**: Package management
- **Persistent Volumes**: Storage dur√°vel

### **üìä Observability Stack**
- **Micrometer**: M√©tricas
- **Prometheus**: Coleta de m√©tricas
- **Grafana**: Dashboards (impl√≠cito)
- **Logstash Encoder**: Structured logging
- **Resilience4j**: Circuit breaker

---

## üéØ **Fluxo Completo - Exemplo Pr√°tico**

### **üì§ Request Example**
```bash
curl -X POST http://kbnt-log-service:8080/api/v1/logs \
  -H "Content-Type: application/json" \
  -H "X-Correlation-ID: txn-12345" \
  -d '{
    "level": "ERROR",
    "message": "Payment processing failed for transaction",
    "serviceName": "payment-service",
    "category": "FINANCIAL",
    "userId": "user123",
    "metadata": {
      "transactionId": "txn-12345",
      "amount": 150.00,
      "currency": "USD"
    }
  }'
```

### **üîÑ Processing Flow**
1. **Controller** recebe POST ‚Üí valida payload
2. **Producer** enriquece mensagem ‚Üí adiciona timestamp, correlationId
3. **Router** determina topic ‚Üí `kbnt-financial-logs` (categoria FINANCIAL)
4. **Kafka Producer** envia ‚Üí partition calculada por `payment-service-ERROR`
5. **AMQ Streams** persiste ‚Üí replication factor 3, compression lz4
6. **Response** retorna ‚Üí HTTP 202 com metadata do Kafka

### **üì• Response Example**
```json
{
  "status": "accepted",
  "correlationId": "txn-12345",
  "topic": "kbnt-financial-logs",
  "partition": 2,
  "offset": 12847
}
```

Este workflow representa um sistema **enterprise-grade** para processamento de logs com **alta disponibilidade**, **performance otimizada** e **observabilidade completa**! üöÄ
