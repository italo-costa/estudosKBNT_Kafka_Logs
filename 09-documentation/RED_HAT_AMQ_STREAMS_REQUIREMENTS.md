# Red Hat AMQ Streams - Requisitos de Ambiente

## üìã Vis√£o Geral
Red Hat AMQ Streams √© a distribui√ß√£o enterprise do Apache Kafka fornecida pela Red Hat, baseada no projeto Strimzi para Kubernetes/OpenShift.

## üéØ Op√ß√µes de Deployment

### 1. Red Hat AMQ Streams no OpenShift/Kubernetes
**Recomendado para Produ√ß√£o Enterprise**

#### Requisitos M√≠nimos:
- **OpenShift 4.8+** ou **Kubernetes 1.21+**
- **3+ n√≥s** para alta disponibilidade
- **8GB RAM** por n√≥ m√≠nimo
- **100GB storage** persistente por broker
- **Red Hat subscription** ativa

#### Componentes Principais:
```yaml
# Cluster Operator
apiVersion: kafka.strimzi.io/v1beta2
kind: Kafka
metadata:
  name: kbnt-kafka-cluster
spec:
  kafka:
    version: 3.4.0
    replicas: 3
    listeners:
      - name: plain
        port: 9092
        type: internal
        tls: false
      - name: tls
        port: 9093
        type: internal
        tls: true
    storage:
      type: persistent-claim
      size: 100Gi
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 10Gi
  entityOperator:
    topicOperator: {}
    userOperator: {}
```

### 2. Red Hat AMQ Streams Standalone (N√£o-Kubernetes)
**Para Desenvolvimento e Testes**

#### Requisitos:
- **RHEL 8/9** ou **CentOS Stream**
- **Java 11** ou **Java 17**
- **4GB RAM** m√≠nimo
- **50GB storage**
- **Red Hat subscription** para downloads oficiais

#### Estrutura de Diret√≥rios:
```
/opt/amq-streams/
‚îú‚îÄ‚îÄ bin/           # Scripts de inicializa√ß√£o
‚îú‚îÄ‚îÄ config/        # Configura√ß√µes
‚îú‚îÄ‚îÄ libs/          # Bibliotecas Java
‚îî‚îÄ‚îÄ logs/          # Logs do sistema
```

### 3. Apache Kafka Open Source (Alternativa Gratuita)
**Para Desenvolvimento Local**

#### Vantagens:
- ‚úÖ **Gratuito** e open source
- ‚úÖ **Compat√≠vel** com AMQ Streams
- ‚úÖ **F√°cil instala√ß√£o** local
- ‚úÖ **Mesmo protocolo** e APIs

#### Desvantagens vs AMQ Streams:
- ‚ùå Sem suporte enterprise Red Hat
- ‚ùå Sem ferramentas de gerenciamento avan√ßadas
- ‚ùå Sem integra√ß√£o nativa OpenShift
- ‚ùå Configura√ß√£o manual necess√°ria

## üöÄ Op√ß√µes de Setup para o Projeto KBNT

### Op√ß√£o 1: AMQ Streams no OpenShift (Produ√ß√£o)
```bash
# 1. Instalar AMQ Streams Operator
oc apply -f https://operatorhub.io/install/amq-streams.yaml

# 2. Criar namespace
oc new-project kbnt-kafka

# 3. Deploy do cluster Kafka
oc apply -f kafka-cluster.yaml

# 4. Verificar status
oc get kafka kbnt-kafka-cluster -o yaml
```

### Op√ß√£o 2: Kafka Docker Compose (Desenvolvimento)
```yaml
# docker-compose-kafka.yml
version: '3.8'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "9092:9092"
```

### Op√ß√£o 3: Kafka Local (Desenvolvimento Simples)
```powershell
# Download Apache Kafka
wget https://downloads.apache.org/kafka/2.13-3.4.0/kafka_2.13-3.4.0.tgz

# Extrair
tar -xzf kafka_2.13-3.4.0.tgz

# Iniciar Zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties

# Iniciar Kafka
bin/kafka-server-start.sh config/server.properties
```

## üîß Configura√ß√£o para Microservi√ßos Spring Boot

### application.yml dos Microservi√ßos:
```yaml
spring:
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
    consumer:
      group-id: ${spring.application.name}
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer

management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
```

### T√≥picos Necess√°rios para KBNT:
```bash
# Criar t√≥picos
kafka-topics.sh --create --topic user-events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics.sh --create --topic order-events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics.sh --create --topic payment-events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics.sh --create --topic inventory-events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics.sh --create --topic notification-events --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
kafka-topics.sh --create --topic audit-logs --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
```

## üéØ Recomenda√ß√£o para o Projeto Atual

### Para Desenvolvimento (Fase Atual):
1. **Apache Kafka via Docker Compose** 
   - R√°pido de configurar
   - Compat√≠vel com AMQ Streams
   - Permite testar todos os recursos

### Para Produ√ß√£o (Futuro):
1. **Red Hat AMQ Streams no OpenShift**
   - Suporte enterprise
   - Alta disponibilidade
   - Monitoramento avan√ßado

## üì¶ Scripts de Setup Autom√°tico

### setup-kafka-docker.ps1:
```powershell
# Baixar e iniciar Kafka via Docker
docker-compose -f docker-compose-kafka.yml up -d

# Aguardar inicializa√ß√£o
Start-Sleep -Seconds 30

# Criar t√≥picos
foreach ($topic in @('user-events','order-events','payment-events','inventory-events','notification-events','audit-logs')) {
    docker exec kafka kafka-topics --create --topic $topic --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
}

Write-Host "‚úÖ Kafka environment ready!"
```

## üîç Verifica√ß√£o do Ambiente

### Health Checks:
```bash
# Verificar se Kafka est√° rodando
curl -f http://localhost:8082/topics || echo "Kafka REST not available"

# Listar t√≥picos
kafka-topics.sh --list --bootstrap-server localhost:9092

# Testar produ√ß√£o/consumo
kafka-console-producer.sh --topic test --bootstrap-server localhost:9092
kafka-console-consumer.sh --topic test --from-beginning --bootstrap-server localhost:9092
```

## üí∞ Custos e Licen√ßas

### Red Hat AMQ Streams:
- **Licen√ßa Red Hat** necess√°ria
- **Suporte incluso**
- **~$2000-5000/ano** por inst√¢ncia

### Apache Kafka Open Source:
- **Gratuito**
- **Suporte comunidade**
- **Compat√≠vel 100%** com AMQ Streams

## ‚úÖ Pr√≥ximos Passos Recomendados

1. **Configurar Kafka Docker** para desenvolvimento
2. **Testar conex√£o** dos microservi√ßos
3. **Validar t√≥picos** e mensagens
4. **Implementar monitoramento** b√°sico
5. **Planejar migra√ß√£o** para AMQ Streams quando necess√°rio

---
**Conclus√£o**: Para o projeto atual, recomendo iniciar com **Apache Kafka via Docker** que oferece compatibilidade total com Red Hat AMQ Streams, permitindo desenvolvimento e testes sem custos de licen√ßa.
