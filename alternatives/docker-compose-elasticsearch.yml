version: '3.8'

services:
  # Elasticsearch cluster
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: kbnt-elasticsearch
    environment:
      - node.name=kbnt-elasticsearch
      - cluster.name=kbnt-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - action.destructive_requires_name=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - kbnt-elasticsearch-data:/usr/share/elasticsearch/data
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - kbnt-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Kibana for visualization
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kbnt-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - SERVER_NAME=kbnt-kibana
      - SERVER_HOST=0.0.0.0
    ports:
      - "5601:5601"
    networks:
      - kbnt-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Redis for fast duplicate detection cache
  redis:
    image: redis:7-alpine
    container_name: kbnt-redis
    ports:
      - "6379:6379"
    volumes:
      - kbnt-redis-data:/data
    networks:
      - kbnt-network
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Kafka (Red Hat AMQ Streams compatible)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: kbnt-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - kbnt-network
    volumes:
      - kbnt-zookeeper-data:/var/lib/zookeeper/data

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kbnt-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    networks:
      - kbnt-network
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_MS: 604800000  # 7 days
      KAFKA_LOG_SEGMENT_BYTES: 104857600  # 100MB
    volumes:
      - kbnt-kafka-data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:29092"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Logstash for log processing (optional)
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: kbnt-logstash
    environment:
      - xpack.monitoring.enabled=false
      - LS_JAVA_OPTS=-Xms512m -Xmx512m
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
    ports:
      - "5044:5044"
      - "9600:9600"
    networks:
      - kbnt-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # Filebeat for log shipping (optional)
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: kbnt-filebeat
    user: root
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - KIBANA_HOST=http://kibana:5601
    volumes:
      - ./filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - kbnt-filebeat-data:/usr/share/filebeat/data
    networks:
      - kbnt-network
    depends_on:
      elasticsearch:
        condition: service_healthy

  # KBNT Producer Service
  kbnt-producer:
    build:
      context: ../../microservices/kbnt-stock-producer-service
      dockerfile: Dockerfile
    container_name: kbnt-producer-service
    ports:
      - "8080:8080"
    networks:
      - kbnt-network
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  # KBNT Consumer Service with Elasticsearch
  kbnt-consumer:
    build:
      context: ../../microservices/kbnt-stock-consumer-service
      dockerfile: Dockerfile.elasticsearch
    container_name: kbnt-consumer-service
    ports:
      - "8081:8081"
    networks:
      - kbnt-network
    environment:
      - SPRING_PROFILES_ACTIVE=docker,elasticsearch
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - ELASTICSEARCH_INDEX_PATTERN=kbnt-consumption-logs
      - ELASTICSEARCH_ENABLED=true
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/api/consumer/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  # Prometheus for metrics collection (optional)
  prometheus:
    image: prom/prometheus:latest
    container_name: kbnt-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - kbnt-prometheus-data:/prometheus
    networks:
      - kbnt-network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'

  # Grafana for metrics visualization (optional)
  grafana:
    image: grafana/grafana:latest
    container_name: kbnt-grafana
    ports:
      - "3000:3000"
    volumes:
      - kbnt-grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - kbnt-network
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false

volumes:
  kbnt-elasticsearch-data:
    driver: local
  kbnt-redis-data:
    driver: local
  kbnt-zookeeper-data:
    driver: local
  kbnt-kafka-data:
    driver: local
  kbnt-filebeat-data:
    driver: local
  kbnt-prometheus-data:
    driver: local
  kbnt-grafana-data:
    driver: local

networks:
  kbnt-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
